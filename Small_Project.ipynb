{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1851,"status":"ok","timestamp":1616065109430,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"-X2n5bQSytz7","outputId":"8beb2b48-e002-4313-fe8c-3acb1fa551ed"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23115,"status":"ok","timestamp":1615957086692,"user":{"displayName":"Huiqing Lin","photoUrl":"","userId":"15292081928935485100"},"user_tz":-480},"id":"6ShpRaGFy7CX","outputId":"930b0d6d-ed57-4d80-c2bb-0b7cebc669b7"},"outputs":[],"source":["!git clone https://github.com/LinHuiqing/50.039-TheoryAndPracticeOfDeepLearning-SmallProject.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":854,"status":"ok","timestamp":1616065111982,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"7DiY72UhPBvZ","outputId":"75db15e1-5b23-4960-9e08-81028e6b6622"},"outputs":[],"source":["cd /content/gdrive/MyDrive/50.039-TheoryAndPracticeOfDeepLearning-SmallProject"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1204,"status":"ok","timestamp":1616065113930,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"kUOn1hC5zJEW"},"outputs":[],"source":["# Matplotlib\n","import matplotlib.pyplot as plt\n","# Numpy\n","import numpy as np\n","# Pillow\n","from PIL import Image\n","# Torch\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import transforms\n","\n","# tqdm\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{"id":"z4RYfn0k6QeW"},"source":["2.a. Creating a global Dataset object\n","Let us start this part by creating a general Dataset object, called Lung_Dataset.\n","It starts with of a constructor, which simply gathers the key parameters we listed in Part 1., into attributes of the object.\n","Second, a describe method is provided, which simply displays a few details regarding the dataset. Note that a describe function like this one is often considered good practice, as it provides any developer with details about the dataset, at a glance.\n","Third, an open_image method is provided, an will open the image defined by the combination of parameters defined in (group_val, class_val, index_val). For instance, if group_val is set to 'train', class val is set to 'normal' and index_val set to 3, the function will load the image in ./dataset_demo/train/normal/3.jpg. Note that the open_image method has a few asserts designed to cover for unexpected values for (group_val, class_val, index_val).\n","Finally, it contains a show_img method, which will open the image for the parameters in (group_val, class_val, index_val), and will display it on screen, using matplotlib.\n","Our full general Dataset object, Lung_Dataset, is shown below. Note that it inherits from the Dataset class from the torch.utils.data library."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":967,"status":"ok","timestamp":1616063343164,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"mQ7tvxGA2AkK"},"outputs":[],"source":["class Lung_Dataset(Dataset):\n","    \"\"\"\n","    Generic Dataset class.\n","    \"\"\"\n","    \n","    def __init__(self):\n","        \"\"\"\n","        Constructor for generic Dataset class - simply assembles\n","        the important parameters in attributes.\n","        \"\"\"\n","        \n","        # All images are of size 150 x 150\n","        self.img_size = (150, 150)\n","        \n","        # Only two classes will be considered here (normal and infected)\n","        self.classes = {0: 'normal', 1: 'infected_covid', 2: 'infected_noncovid'}\n","        \n","        # The dataset has been split in training, testing and validation datasets\n","        self.groups = ['train', 'test', 'val']\n","        \n","        # Number of images in each part of the dataset\n","        self.dataset_numbers = {'train_normal': 1341,\\\n","                                'train_infected_covid': 1345,\\\n","                                'train_infected_noncovid': 2530,\\\n","                                'val_normal': 8,\\\n","                                'val_infected_covid': 9,\\\n","                                'val_infected_noncovid': 8,\\\n","                                'test_normal': 234,\\\n","                                'test_infected_covid': 139,\\\n","                                'test_infected_noncovid': 242}\n","        \n","        # Path to images for different parts of the dataset\n","        self.dataset_paths = {'train_normal': './dataset/train/normal/',\\\n","                              'train_infected_covid': './dataset/train/infected/covid/',\\\n","                              'train_infected_noncovid': './dataset/train/infected/non-covid/',\\\n","                              'val_normal': './dataset/val/normal/',\\\n","                              'val_infected_covid': './dataset/val/infected/covid/',\\\n","                              'val_infected_noncovid': './dataset/val/infected/non-covid/',\\\n","                              'test_normal': './dataset/test/normal/',\\\n","                              'test_infected_covid': './dataset/test/infected/covid/',\\\n","                              'test_infected_noncovid': './dataset/test/infected/non-covid/'}\n","        \n","        \n","    def describe(self):\n","        \"\"\"\n","        Descriptor function.\n","        Will print details about the dataset when called.\n","        \"\"\"\n","        \n","        # Generate description\n","        msg = \"This is the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class\"\n","        msg += \" in Feb-March 2021. \\n\"\n","        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n","        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n","        msg += \"Images have been split in three groups: training, testing and validation sets.\\n\"\n","        msg += \"The images are stored in the following locations \"\n","        msg += \"and each one contains the following number of images:\\n\"\n","        for key, val in self.dataset_paths.items():\n","            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n","        print(msg)\n","        \n","\n","    def show_distribution(self):\n","        \"\"\"\n","        Plotting function.\n","        Will plot the graphs showing the distribution of images among classes when called.\n","        \"\"\"\n","        # Data to plot\n","        data = [list(self.dataset_numbers.values())[0:3], list(self.dataset_numbers.values())[3:6], list(self.dataset_numbers.values())[6:9]]\n","        labels = []\n","        for key, value in self.classes.items():\n","            labels.append(\"Class {}:\\n{}\".format(key, value))\n","        \n","        # Format plot area\n","        X = np.arange(len(labels))\n","        width = 0.15\n","        fig, ax = plt.subplots()\n","        rects1 = ax.bar(X - width, data[0], width , label = 'train')\n","        rects2 = ax.bar(X, data[1], width, label='validation')\n","        rects3 = ax.bar(X + width, data[2], width, label = 'test')\n","        fig.tight_layout()\n","        fig.set_size_inches(18.5, 10.5)\n","\n","        # Add plot title, y-axis label, custom x-axis tick labels\n","        ax.set_ylabel('Number of images', fontsize = 17)\n","        ax.set_title('Number of images by dataset type and class', fontsize = 17)\n","        ax.set_xticks(X)\n","        ax.set_xticklabels(labels, Fontsize = 17)\n","        ax.legend(fontsize = 17)\n","\n","        # Display plot\n","        plt.yticks(fontsize = 15)\n","        plt.show()\n","\n","        # Save figure\n","        filename = 'Image_Distribution.png'\n","        fig.savefig(filename, dpi=100)\n","        print(\"Plot has been saved as {} in the submission folder.\".format(filename))\n","\n","\n","    def open_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'train', 'test' or 'val'.\n","        - class_val variable should be set to 'normal' or 'infected'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \n","        Returns loaded image as a normalized Numpy array.\n","        \"\"\"\n","        \n","        # Asserts checking for consistency in passed parameters\n","        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n","        assert group_val in self.groups, err_msg\n","        \n","        err_msg = \"Error - class_val variable should be set to 'normal' or 'infected'.\"\n","        assert class_val in self.classes.values(), err_msg\n","        \n","        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n","        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n","        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n","        assert isinstance(index_val, int), err_msg\n","        assert index_val >= 0 and index_val <= max_val, err_msg\n","        \n","        # Open file as before\n","        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n","        with open(path_to_file, 'rb') as f:\n","            # Convert to Numpy array and normalize pixel values by dividing by 255.\n","            im = np.asarray(Image.open(f))/255\n","        f.close()\n","        return im\n","    \n","    \n","    def show_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens, then displays image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'train', 'test' or 'val'.\n","        - class_val variable should be set to 'normal' or 'infected'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \"\"\"\n","        \n","        # Open image\n","        im = self.open_img(group_val, class_val, index_val)\n","        \n","        # Display\n","        plt.imshow(im)"]},{"cell_type":"markdown","metadata":{"id":"NO9FWxqv6cjV"},"source":["It can simply be called, and a generic description can be displayed."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":643},"executionInfo":{"elapsed":1456,"status":"ok","timestamp":1616063351728,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"XzlwD2LB6f2A","outputId":"e1e646f2-2807-46f5-b665-13bf87121c50"},"outputs":[],"source":["ld_general = Lung_Dataset()\n","ld_general.describe()\n","im = ld_general.open_img('train', 'normal', 1)\n","print(im.shape)\n","print(im)\n","ld_general.show_img('train', 'normal', 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":769},"executionInfo":{"elapsed":1264,"status":"ok","timestamp":1616063356685,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"PFm_WmEQhR6Y","outputId":"2d257c92-3331-49c5-8992-3b3f270c7d5e"},"outputs":[],"source":["ld_general.show_distribution()"]},{"cell_type":"markdown","metadata":{"id":"SGLSnlLQ6sKU"},"source":["2.b. Creating a train Dataset object\n","In practice however, one likes to define several datasets, for each subgroup (train, test, validation). This class however, will only be used to load images from the ./dataset_demo/train/ folder. It woks roughly as the previous Lung_Dataset class. In practice, we could have inherited Lung_Train_Dataset from Lung_Dataset, but we normally do not bother creating a general Dataset object like Lung_Dataset in Section 2.a.\n","The Lung_Train_Dataset object resembles to the Lung_Dataset as it contains restricted versions of the same attributes we had in the Lung_Dataset object.\n","It however contains two additional (special) methods, which need to be defined if we want to transform our Lung_Train_Dataset object into a dataloader later on.\n","The first method is the special length method ( len ), which should return the number of images present in the dataset. Lucky for us, it can be easily computed using the dataset_numbers attribute of our object.\n","The second one is the special getitem method ( getitem ), which is used to fetch an image and its label, using a single index value.\n","By convention here, we have decided to open the image in ./dataset_demo/train/normal/XXX.jpg, if the value in XXX is strictly lower than 36, which is the number of images in the ./dataset_demo/train/normal/ folder.\n","Otherwise, we open the image in ./dataset_demo/train/infected/YYY.jpg, where YYY is simply defined as YYY = XXX - 36.\n","Note that if the value in XXX is larger than the length of the dataset, i.e. 36 + 34 = 70, then no image will be opened and the getitem will display an error, based on the asserts we have in the open_img method.\n","Finally, the getitem method will return the image, along with a one-hot vector corresponding to the class of the object, i.e. [1, 0] for normal class and [0, 1] for infected class. Both returned parameters will be torch tensors."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":872,"status":"ok","timestamp":1616068360183,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"PGH6oyLpCQyZ"},"outputs":[],"source":["class Lung_Train_Dataset(Dataset):\n","    \n","    def __init__(self, transformations_list, normalize = None):\n","        \"\"\"\n","        Constructor for the Training Dataset class - simply assembles\n","        the important parameters in attributes.\n","        \"\"\"\n","        \n","        # All images are of size 150 x 150\n","        self.img_size = (150, 150)\n","        \n","        # Three classes will be considered here (normal, infected_covid, and infected_noncovid)\n","        self.classes = {0: 'normal', 1: 'infected_covid', 2: 'infected_noncovid'}\n","        \n","        # The dataset consists only of training images\n","        self.groups = 'train'\n","        \n","        # Number of images in each part of the original dataset\n","        self.og_dataset_numbers = {'train_normal': 1341,\\\n","                                'train_infected_covid': 1345,\\\n","                                'train_infected_noncovid': 2530}\n","\n","        # Number of images in each part of the extended dataset\n","        self.extended_dataset_numbers = {'train_normal': 2682,\\\n","                                'train_infected_covid': 2690,\\\n","                                'train_infected_noncovid': 5060}\n","        \n","        # Path to images for different parts of the original dataset\n","        self.dataset_paths = {'train_normal': './dataset/train/normal/',\\\n","                              'train_infected_covid': './dataset/train/infected/covid/',\\\n","                              'train_infected_noncovid': './dataset/train/infected/non-covid/'}\n","\n","        self.transform = transforms.Compose(transformations_list)   \n","\n","        self.normalize = normalize                                        \n","        \n","    def describe(self):\n","        \"\"\"\n","        Descriptor function.\n","        Will print details about the dataset when called.\n","        \"\"\"\n","        \n","        # Generate description\n","        msg = \"This is the training dataset of the Lung Dataset\"\n","        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n","        msg += \" in Feb-March 2021. \\n\"\n","        msg += \"The original dataset (before data augmentation) contains a total of {} images, \".format(sum(self.og_dataset_numbers.values()))\n","        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n","        msg += \"The images are stored in the following locations \"\n","        msg += \"and each one contains the following number of images:\\n\"\n","        for key, val in self.dataset_paths.items():\n","            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.og_dataset_numbers[key])\n","        msg += \"Data augmentation was performed to extended the training dataset. Each image was transformed once to produce a new image, \"\n","        msg += \"hence the total\\nnumber of images in the extended dataset is twice the number in the original dataset, i.e. {}.\\n\".format(sum(self.extended_dataset_numbers.values()))\n","        msg += \"Please note that data augmentation is only performed and transformed images are only retrieved when the dataset is loaded. \"\n","        msg += \"The augmented\\ndata are not saved to files.\"\n","        print(msg)\n","\n","    \n","    def open_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'train', 'test' or 'val'.\n","        - class_val variable should be set to 'normal' or 'infected'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \n","        Returns loaded image as a normalized Numpy array.\n","        \"\"\"\n","        \n","        # Asserts checking for consistency in passed parameters\n","        err_msg = \"Error - group_val variable should be set to 'train'.\"\n","        assert group_val in self.groups, err_msg\n","        \n","        err_msg = \"Error - class_val variable should be set to 'normal', 'infected_covid', or 'infected_noncovid.\"\n","        assert class_val in self.classes.values(), err_msg\n","        \n","        max_val = self.og_dataset_numbers['{}_{}'.format(group_val, class_val)]\n","        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n","        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n","        assert isinstance(index_val, int), err_msg\n","        assert index_val >= 0 and index_val <= max_val, err_msg\n","        \n","        # Open file as before\n","        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n","        with open(path_to_file, 'rb') as f:\n","            im = np.asarray(Image.open(f))/255\n","        f.close()\n","        return im\n","\n","    \n","    def show_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens, then displays image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'train', 'test' or 'val'.\n","        - class_val variable should be set to 'normal' or 'infected'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in the original dataset.\n","        \"\"\"\n","        \n","        # Open image\n","        im = self.open_img(group_val, class_val, index_val)\n","        \n","        # Display\n","        plt.imshow(im)\n","\n","           \n","    def __len__(self):\n","        \"\"\"\n","        Length special method, returns the number of images in the extended dataset.\n","        \"\"\"\n","        \n","        # Length function\n","        return sum(self.extended_dataset_numbers.values())\n","    \n","    \n","    def __getitem__(self, index):\n","        \"\"\"\n","        Getitem special method.\n","        \n","        Expects an integer value index, between 0 and len(self) - 1.\n","        \n","        Convention:\n","        - open the image in ./dataset/train/normal/XXX.jpg if XXX is strictly lower than 1341 (number of images in the ./dataset/train/normal/ folder)\n","        - transform the image in ./dataset/train/normal/YYY.jpg if XXX is between 1341 (inclusive) and 2682 (exclusive) (twice the number of\n","          images in the ./dataset/train/normal/ folder), where YYY = XXX - 1341.\n","        - open the image in ./dataset/train/infected/covid/YYY.jpg if XXX is between 2682 (inclusive) (total number of images in class 0: normal after\n","          augmentation) and  4027 (exclusive) (4027 - 2682 = 1345 number of images in the ./dataset/train/infected/covid/ folder), where YYY = XXX - 2682.\n","        - transform the image in ./dataset/train/infected/covid/YYY.jpg if XXX is between 4027 (inclusive) and 5372 (exclusive) (total number of images in\n","          class 0: normal and class 1: infected_covid after augmentation), where YYY = XXX - 2682 - 1345 = XXX - 4027.\n","        - open the image in ./dataset/train/infected/non-covid/ folder if XXX is between 5372 (inclusive) (total number of images in class 0: normal after\n","          and class 1: infected_covid after augmentation) and  7902 (exclusive) (7902 - 5372 = 2530 number of images in the ./dataset/train/infected/non-covid/\n","          folder), where YYY = XXX - 2682 - 2690 = XXX - 5372.\n","        - transform the image in ./dataset/train/infected/non-covid/YYY.jpg if XXX is between 7902 (inclusive) and 10432 (exclusive) (total number of images in\n","          all classes after augmentation), where YYY = XXX - 5372 - 2530 = XXX - 7902.\n","\n","        \n","        Returns the image and its label as a one hot vector, both in torch tensor format in dataset.\n","        \"\"\"\n","\n","        # Get item special method\n","        first_val = int(list(self.og_dataset_numbers.values())[0]) # number of images in class 0: normal = 1341\n","        second_val = int(list(self.og_dataset_numbers.values())[1]) # number of images in class 1: infected_covid = 1345\n","        third_val = int(list(self.og_dataset_numbers.values())[2]) # number of images in class 2: infected_noncovid = 2530\n","        if index < first_val*2: # not inclusive because image labelling starts from 0, not 1\n","            class_val = 'normal'\n","            label = torch.Tensor([1, 0, 0])\n","            if index < first_val:\n","                im = self.open_img(self.groups, class_val, index)\n","                im = transforms.functional.to_tensor(im).float()\n","            else:\n","                adjusted_index = index-first_val\n","                im = self.open_img(self.groups, class_val, adjusted_index)\n","                im = transforms.functional.to_tensor(im).float()\n","                im = self.transform(im)\n","\n","        elif (first_val*2) <= index < (first_val + second_val)*2:\n","            index -= first_val*2\n","            class_val = 'infected_covid'\n","            label = torch.Tensor([0, 1, 0])\n","            if index < second_val:\n","                im = self.open_img(self.groups, class_val, index)\n","                im = transforms.functional.to_tensor(im).float()\n","            else:\n","                adjusted_index = index - second_val\n","                im = self.open_img(self.groups, class_val, adjusted_index)\n","                im = transforms.functional.to_tensor(im).float()\n","                im = self.transform(im)\n","\n","        else:\n","            index -= (first_val + second_val)\n","            class_val = 'infected_noncovid'\n","            index -= (first_val + second_val)\n","            label = torch.Tensor([0, 0, 1])\n","            if index < third_val:\n","                im = self.open_img(self.groups, class_val, index)\n","                im = transforms.functional.to_tensor(im).float()\n","            else:\n","                adjusted_index = index - third_val\n","                im = self.open_img(self.groups, class_val, adjusted_index)\n","                im = transforms.functional.to_tensor(im).float()\n","                im = self.transform(im)\n","        \n","        if self.normalize != None:\n","            mean = self.normalize[0]\n","            std = self.normalize[1]\n","            normalization = transforms.Normalize((mean), (std))\n","            im = normalization(im)\n","        return im, label"]},{"cell_type":"markdown","metadata":{"id":"vW7lC2cz7aHI"},"source":["We can then create our Dataset object as before and display a description of the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":839,"status":"ok","timestamp":1616068364461,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"hgAgLUU97XpU","outputId":"83cf0b7a-b51d-4a35-8e03-d7d95bc7adb4"},"outputs":[],"source":["transformation_list = [transforms.RandomAffine(degrees = 15, translate = (5/150, 5/150), scale=(9/8, 9/8), shear=None),\\\n","                       transforms.GaussianBlur(kernel_size = 3, sigma=(0.1, 2.0))]\n","ld_train = Lung_Train_Dataset(transformation_list) # extended dataset\n","ld_train.describe()\n","print(len(ld_train)) # gives total number of images in the extended train dataset"]},{"cell_type":"markdown","metadata":{"id":"htzb78Uh7sdg"},"source":["Using the getitem method (i.e. using square bracket indexing on our object) will produce a 150 by 150 torch tensor corresponding to our image, with normalize values. It also produces a one-hot vector, in torch tensor format as well."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":770,"status":"ok","timestamp":1615992239835,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"UEMN9rKj7vXU","outputId":"4518b721-241f-47b0-ddbb-4305ffc4bfe4"},"outputs":[],"source":["im, class_oh = ld_train[1360] # index = 1360 > 1341 so look at elif statement: 1360 - 1341 = 19 (label of image in infected_covid class)\n","print(im.shape)\n","print(im)\n","print(class_oh)"]},{"cell_type":"markdown","metadata":{"id":"hX0uysZQ7xaB"},"source":["2.c. Creating a test and val Dataset object\n","Following the same logic in Section 2.b., we can create a Lung_Test_Dataset and a Lung_Val_Dataset object. They operate in the exact same manner as the Lung_Train_Dataset object from Section 2.b., but working on a different subfolder."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":970,"status":"ok","timestamp":1616069129293,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"1r2EPs8g7ziH"},"outputs":[],"source":["class Lung_Test_Dataset(Dataset):\n","    \n","    def __init__(self, normalize = None):\n","        \"\"\"\n","        Constructor for generic Dataset class - simply assembles\n","        the important parameters in attributes.\n","        \"\"\"\n","        \n","        # All images are of size 150 x 150\n","        self.img_size = (150, 150)\n","        \n","        # Only two classes will be considered here (normal and infected)\n","        self.classes = {0: 'normal', 1: 'infected_covid', 2: 'infected_noncovid'}\n","        \n","        # The dataset consists only of test images\n","        self.groups = 'test'\n","        \n","        # Number of images in each part of the dataset\n","        self.dataset_numbers = {'test_normal': 234,\\\n","                                'test_infected_covid': 139,\\\n","                                'test_infected_noncovid':242 }\n","        \n","        # Path to images for different parts of the dataset\n","        self.dataset_paths = {'test_normal': './dataset/test/normal/',\\\n","                              'test_infected_covid': './dataset/test/infected/covid',\\\n","                              'test_infected_noncovid': './dataset/test/infected/non-covid'}\n","        \n","        self.normalize = normalize\n","        \n","    def describe(self):\n","        \"\"\"\n","        Descriptor function.\n","        Will print details about the dataset when called.\n","        \"\"\"\n","        \n","        # Generate description\n","        msg = \"This is the test dataset of the Lung Dataset\"\n","        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n","        msg += \" in Feb-March 2021. \\n\"\n","        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n","        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n","        msg += \"The images are stored in the following locations \"\n","        msg += \"and each one contains the following number of images:\\n\"\n","        for key, val in self.dataset_paths.items():\n","            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n","        print(msg)\n","        \n","    \n","    def open_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'test'.\n","        - class_val variable should be set to 'normal', 'infected_covid', or 'infected_noncovid'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \n","        Returns loaded image as a normalized Numpy array.\n","        \"\"\"\n","        \n","        # Asserts checking for consistency in passed parameters\n","        err_msg = \"Error - group_val variable should be set to 'test'.\"\n","        assert group_val in self.groups, err_msg\n","        \n","        err_msg = \"Error - class_val variable should be set to 'normal', 'infected_covid', or 'infected_noncovid'.\"\n","        assert class_val in self.classes.values(), err_msg\n","        \n","        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n","        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n","        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n","        assert isinstance(index_val, int), err_msg\n","        assert index_val >= 0 and index_val <= max_val, err_msg\n","        \n","        # Open file as before\n","        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n","        with open(path_to_file, 'rb') as f:\n","            im = np.asarray(Image.open(f))/255\n","        f.close()\n","        return im\n","    \n","    \n","    def show_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens, then displays image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'test'.\n","        - class_val variable should be set to 'normal', 'infected_covid, or 'infected_noncovid'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \"\"\"\n","        \n","        # Open image\n","        im = self.open_img(group_val, class_val, index_val)\n","        \n","        # Display\n","        plt.imshow(im)\n","        \n","        \n","    def __len__(self):\n","        \"\"\"\n","        Length special method, returns the number of images in dataset.\n","        \"\"\"\n","        \n","        # Length function\n","        return sum(self.dataset_numbers.values())\n","    \n","    \n","    def __getitem__(self, index):\n","        \"\"\"\n","        Getitem special method.\n","        \n","        Expects an integer value index, between 0 and len(self) - 1.\n","        \n","        Convention:\n","        - open the image in ./dataset/test/normal/XXX.jpg if XXX is strictly lower than 234 (number of images in the ./dataset/test/normal/ folder)\n","        - open the image in ./dataset/test/infected/YYY.jpg if XXX is between 234 (inclusive) and 373 (exclusive) (total number of images in \n","          ./dataset/test/normal and ./dataset/test/infected/covid/ folders), where YYY is defined as YYY = XXX - 234.\n","        - otherwise, open the image in ./dataset/test/infected/non-covid/ folder \n","\n","        Returns the image and its label as a one hot vector, both\n","        in torch tensor format in dataset.\n","        \"\"\"\n","        \n","        # Get item special method\n","        first_val = int(list(self.dataset_numbers.values())[0])\n","        second_val = int(list(self.dataset_numbers.values())[1])\n","        if index < first_val:\n","            class_val = 'normal'\n","            label = torch.Tensor([1, 0, 0])\n","        elif first_val <= index < first_val + second_val:\n","            index -= first_val\n","            class_val = 'infected_covid'\n","            label = torch.Tensor([0, 1, 0])\n","        else:\n","            class_val = 'infected_noncovid'\n","            index -= (first_val + second_val)\n","            label = torch.Tensor([0, 0, 1])\n","        im = self.open_img(self.groups, class_val, index)\n","        im = transforms.functional.to_tensor(np.array(im)).float()\n","\n","        if self.normalize != None:\n","            mean = self.normalize[0]\n","            std = self.normalize[1]\n","            normalization = transforms.Normalize((mean), (std))\n","            im = normalization(im)\n","        return im, label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1036,"status":"ok","timestamp":1616069133899,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"p-HrLKUN8hae","outputId":"ee70cc0f-2acf-4449-faf6-01abc5baaad0"},"outputs":[],"source":["ld_test = Lung_Test_Dataset()\n","ld_test.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":902,"status":"ok","timestamp":1616069141066,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"4jLxBD5Y8nc2"},"outputs":[],"source":["class Lung_Val_Dataset(Dataset):\n","    \n","    def __init__(self, normalize = None):\n","        \"\"\"\n","        Constructor for generic Dataset class - simply assembles\n","        the important parameters in attributes.\n","        \"\"\"\n","        \n","        # All images are of size 150 x 150\n","        self.img_size = (150, 150)\n","        \n","        # Only two classes will be considered here (normal and infected)\n","        self.classes = {0: 'normal', 1: 'infected_covid', 2: 'infected_noncovid'}\n","        \n","        # The dataset consists only of validation images\n","        self.groups = 'val'\n","        \n","        # Number of images in each part of the dataset\n","        self.dataset_numbers = {'val_normal': 8,\\\n","                                'val_infected_covid': 9,\\\n","                                'val_infected_noncovid': 8 }\n","        \n","        # Path to images for different parts of the dataset\n","        self.dataset_paths = {'val_normal': './dataset/val/normal/',\\\n","                              'val_infected_covid': './dataset/val/infected/covid',\\\n","                              'val_infected_noncovid': './dataset/val/infected/non-covid'}\n","        \n","        self.normalize = normalize\n","\n","\n","    def describe(self):\n","        \"\"\"\n","        Descriptor function.\n","        Will print details about the dataset when called.\n","        \"\"\"\n","        \n","        # Generate description\n","        msg = \"This is the validation dataset of the Lung Dataset\"\n","        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n","        msg += \" in Feb-March 2021. \\n\"\n","        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n","        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n","        msg += \"The images are stored in the following locations \"\n","        msg += \"and each one contains the following number of images:\\n\"\n","        for key, val in self.dataset_paths.items():\n","            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n","        print(msg)\n","        \n","    \n","    def open_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'val'.\n","        - class_val variable should be set to 'normal', 'infected_covid', or 'infected_noncovid'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \n","        Returns loaded image as a normalized Numpy array.\n","        \"\"\"\n","        \n","        # Asserts checking for consistency in passed parameters\n","        err_msg = \"Error - group_val variable should be set to 'val'.\"\n","        assert group_val in self.groups, err_msg\n","        \n","        err_msg = \"Error - class_val variable should be set to 'normal', 'infected_covid', or 'infected_noncovid'.\"\n","        assert class_val in self.classes.values(), err_msg\n","        \n","        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n","        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n","        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n","        assert isinstance(index_val, int), err_msg\n","        assert index_val >= 0 and index_val <= max_val, err_msg\n","        \n","        # Open file as before\n","        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n","        with open(path_to_file, 'rb') as f:\n","            im = np.asarray(Image.open(f))/255\n","        f.close()\n","        return im\n","    \n","    \n","    def show_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens, then displays image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'val'.\n","        - class_val variable should be set to 'normal', 'infected_covid', or 'infected_noncovid'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \"\"\"\n","        \n","        # Open image\n","        im = self.open_img(group_val, class_val, index_val)\n","        \n","        # Display\n","        plt.imshow(im)\n","        \n","        \n","    def __len__(self):\n","        \"\"\"\n","        Length special method, returns the number of images in dataset.\n","        \"\"\"\n","        \n","        # Length function\n","        return sum(self.dataset_numbers.values())\n","    \n","    \n","    def __getitem__(self, index):\n","        \"\"\"\n","        Getitem special method.\n","        \n","        Expects an integer value index, between 0 and len(self) - 1.\n","        \n","        Convention:\n","        - open the image in ./dataset/val/normal/XXX.jpg if XXX is strictly lower than 8 (number of images in the ./dataset/val/normal/ folder)\n","        - open the image in ./dataset/val/infected/YYY.jpg if XXX is between 8 (inclusive) and 17 (exclusive) (total number of images in \n","          ./dataset/val/normal and ./dataset/val/infected/covid/ folders), where YYY is defined as YYY = XXX - 8.\n","        - otherwise, open the image in ./dataset/val/infected/non-covid/ folder \n","\n","        Returns the image and its label as a one hot vector, both\n","        in torch tensor format in dataset.\n","        \"\"\"\n","        \n","        # Get item special method\n","        first_val = int(list(self.dataset_numbers.values())[0])\n","        second_val = int(list(self.dataset_numbers.values())[1])\n","        if index < first_val:\n","            class_val = 'normal'\n","            label = torch.Tensor([1, 0, 0])\n","        elif first_val <= index < first_val + second_val:\n","            index -= first_val\n","            class_val = 'infected_covid'\n","            label = torch.Tensor([0, 1, 0])\n","        else:\n","            class_val = 'infected_noncovid'\n","            index -= (first_val + second_val)\n","            label = torch.Tensor([0, 0, 1])\n","        im = self.open_img(self.groups, class_val, index)\n","        im = transforms.functional.to_tensor(np.array(im)).float()\n","        \n","        if self.normalize != None:\n","            mean = self.normalize[0]\n","            std = self.normalize[1]\n","            normalization = transforms.Normalize((mean), (std))\n","            im = normalization(im)\n","        return im, label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":871,"status":"ok","timestamp":1616069145568,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"reZWeCUw8rff","outputId":"21fd2d17-e774-4f23-928e-cfe0c7b01b91"},"outputs":[],"source":["ld_val = Lung_Val_Dataset()\n","ld_val.describe()"]},{"cell_type":"markdown","metadata":{"id":"WqVD0w-n8x3W"},"source":["3. Creating a Dataloader object\n","The final step is to create Dataloaders, based on our previous Dataset objects. These Dataloaders will later be used for training, testing and evaluating our models in PyTorch.\n","The dataloaders can be simply created by using the DataLoader object from the torch.utils.data library, and by simply passing it our Dataset object. Additional parameters such as the batch_size (set to 4 for demo here) can be specified. Another interesting parameter is the shuffle = True one, which will randomly shuffle the order in which the images are selected in the Dataset.\n","Additional parameters for the DataLoader can be specified (see https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader for details), but it will not be necessary for this small project."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":762,"status":"ok","timestamp":1616068493123,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"WMJNumWWmf_x"},"outputs":[],"source":["# NORMALISATION\n","def get_mean(data_loader, num_of_pixels):\n","    total_sum = 0\n","    for batch in tqdm(data_loader):\n","        total_sum += batch[0].sum()\n","    mean = total_sum/num_of_pixels\n","    return mean\n","\n","\n","def get_standard_deviation(data_loader, num_of_pixels, mean):\n","    sum_of_squared_error = 0\n","    for batch in tqdm(data_loader):\n","        sum_of_squared_error += ((batch[0]-mean).pow(2)).sum()\n","    std = torch.sqrt(sum_of_squared_error/num_of_pixels)\n","    return std"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["4745c7c8677c4b1da222bb20865454b0","79bb442c13124e479f3cb3cf976ebc54","4adf8674909b46d294bb81f4fe399a9b","5ce8ccdb53c54b3e89259e5f00d0ef08","b404cbff3f2f4b4188d870952579fabc","e9957791eaf843f6803edbcf032e0216","5e962112fdd34eb39d3893a9e6fa1836","5d57beb3500a40ecaf73265ce5c645eb","dd833bfd44f9461aa37701970a2cfe31","bf78b8ea621a43209c06d662aed64b73","cd51f5fd4fec40d7ac1c37d7b66b735f","2c07510cb5ea4421a0d8e24d959dac00","ea9697adc3764b14a6cbe2300755572a","01b6782f5ce64715bd405474adc0b75d","ce96e58e310746ee9c5678d1961febea","47b762d59b734cbdaa0a1a1f156f53c9"]},"executionInfo":{"elapsed":55941,"status":"ok","timestamp":1616069273173,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"W-avozmMMAf-","outputId":"f97c2d04-812a-4628-82a4-ac9df18c4108"},"outputs":[],"source":["# Batch size value to be used (to be decided freely, but set to 4 for demo)\n","bs_val = 4\n","\n","# Dataloader from train dataset\n","train_loader = DataLoader(ld_train, batch_size = bs_val, num_workers = 1, shuffle = True)\n","\n","num_of_pixels = len(ld_train) * 150 * 150  # total number of pixels = number of images * image width * image height\n","train_mean = get_mean(train_loader, num_of_pixels)\n","train_std = get_standard_deviation(train_loader, num_of_pixels, train_mean)\n","\n","print(\"The mean of the extended training dataset before normalisation is {}.\\nThe standard deviation of the extended training dataset before normalisation is {}.\".format(train_mean, train_std))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["9d6184711dfb49988fb7f3e0bc20a2e0","bc4b7269e8c3417bb9e812d1e77892e4","80e3f40f5a294186b75b85d868f74df4","e872c1acec3c4c7bb9cda3ab79e1ca66","0d14401adfec48ceaa132b9af5177a32","c46dc91e0fed45c393de58d6114832e7","67d5e4cbbef446d2ae91fea28e1acbc6","3f888896c37045c89be2896302a892e9","c7eac96b1f0b4965b227933a3f02660d","b193217fbb2848ea88c4f7720178b3be","c6e08c90ffe14f7b81754e9b34edaf18","def83edf8f2b40f9a93355ac08e5b9e1","82105a57910a4f2e8842c4fc65a3194f","fda1167717fb4235beea2a153bb1339d","5bd20aa53a6647008d5766403c38b6d1","439b03ed6e9f420e99b52139b093aef9"]},"executionInfo":{"elapsed":57894,"status":"ok","timestamp":1616069337478,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"b-dajhSo9JW9","outputId":"c7fab5f6-00fe-46b9-8cff-22bef70df08c"},"outputs":[],"source":["# Instantiating a new training dataset to be normalized before training\n","ld_train_normalized = Lung_Train_Dataset(transformation_list, (train_mean, train_std))\n","\n","# Dataloader from normalized train dataset \n","normalized_train_loader = DataLoader(ld_train_normalized, batch_size = bs_val, num_workers = 1, shuffle = True)\n","norm_train_mean = get_mean(normalized_train_loader, num_of_pixels)\n","norm_train_std = get_standard_deviation(normalized_train_loader, num_of_pixels, norm_train_mean)\n","print(\"The mean of the extended training dataset after normalisation is {}.\\nThe standard deviation of the extended training dataset after normalisation is {}.\".format(norm_train_mean, norm_train_std))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455,"referenced_widgets":["e12bdf68a09b47178547b7e7b25195c6","6db8105b70774514a4a52f93bb701216","5676e84b3dfb48169c7ec928ebb2219e","a7f044b572084c5db1bd5f9d26b116af","9d84f5bb64c2413c8f770f5f1c3501ac","27a5f89961764867b8c410f84d7eff8b","aa11c3efded6486fa817631e6100ff38","1db1cd4ef6ec47a39ec49cdcbdfdbad1","90bf363dc92f4e31bbbed60a62a523f6","6ccb88010d5e4ecab53fdac00ad67e96","74fe9c2eb9694790a3e7cdfa29611cfa","221df44f0ca54bb693cbc5979a3f87c7","ccf276a88efd4beba07bc67f1ceadef0","d7f1683ed6774bb9b666731f62636b9d","b4690a0bd73341a8afadf5151d48d9ca","06addbf99ba842928cffb355ff0e5e18"]},"executionInfo":{"elapsed":3517,"status":"ok","timestamp":1616070135765,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"Gny6JFMqPKRV","outputId":"98a97ab7-3714-4f91-85cc-d31d45825c21"},"outputs":[],"source":["# Instantiating a new test dataset to be normalized before testing\n","ld_test_normalized = Lung_Test_Dataset((train_mean, train_std))\n","\n","# Dataloader from normalized test dataset \n","normalized_test_loader = DataLoader(ld_test_normalized, batch_size = bs_val, num_workers = 1, shuffle = True)\n","norm_test_mean = get_mean(normalized_test_loader, num_of_pixels)\n","norm_test_std = get_standard_deviation(normalized_test_loader, num_of_pixels, norm_test_mean)\n","print(\"The mean of the test dataset after normalisation is {}.\\nThe standard deviation of the test dataset after normalisation is {}.\".format(norm_test_mean, norm_test_std))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455,"referenced_widgets":["d0e9c037260b4a648e841aca66230f30","2cc55ef68851456798e6c4ea48b77499","b940f6c6cce1440ab0d2a864a4db5935","be94fa274498483fb94961eb0154ab79","87ac14f07d7e4841847473ce94dae4f8","75d7811d32024ce998317b524dab04f7","01df481d116e4efcb2a78cfb335f7b13","b7dffb49a48f43a58095d6b287cfd12a","39745a6d879b44f0995ca4b441d3f23c","46f77aedb96949f0b3cad782c272f53a","d67ac8f9188a4f00b25a518848ea63a6","e245d050e4f8449bac182e2991a4c12e","1769dacd972248b0b2333706e38e2057","ea8c101a1592401db6f463b78003dac2","38f37aff2bce411c8a1f16694606cd59","9dc146cd31984cecbdf7da71e364d112"]},"executionInfo":{"elapsed":1115,"status":"ok","timestamp":1616070156881,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"d7yj6NBsP8Xl","outputId":"3243aa3f-ee43-41bd-dece-a7ec8874de7d"},"outputs":[],"source":["# Instantiating a new validation dataset to be normalized before testing\n","ld_val_normalized = Lung_Val_Dataset((train_mean, train_std))\n","\n","# Dataloader from validation test dataset \n","normalized_val_loader = DataLoader(ld_val_normalized, batch_size = bs_val, num_workers = 1, shuffle = True)\n","norm_val_mean = get_mean(normalized_val_loader, num_of_pixels)\n","norm_val_std = get_standard_deviation(normalized_val_loader, num_of_pixels, norm_val_mean)\n","print(\"The mean of the validation dataset after normalisation is {}.\\nThe standard deviation of the validation dataset after normalisation is {}.\".format(norm_val_mean, norm_val_std))"]},{"cell_type":"markdown","metadata":{"id":"qPi3smwi89Ma"},"source":["During the training, you will call for mini-batches using a for loop of some sort, probably similar to the one below.\n","Notice how each iteration of the for loop below produces a torch tensor of size [1, bs_val, 150, 150] in v[0] containing the bs_val = 4 images in the current mini-batch. You also have, in v[1], a torch tensor of size [bs_val, 2], containing the one hot vectors for each of the bs_val = 4 images.\n","We voluntarily interrupt it after one iteration of the mini-batch using an assert False."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qC0nk-UD86z1"},"outputs":[],"source":["# Typical mini-batch for loop on dataloader (train)\n","for k, v in enumerate(train_loader):\n","    print(\"-----\")\n","    print(k)\n","    print(v[0])\n","    print(v[1])\n","    # Forced stop\n","    break\n","    #assert False, \"Forced stop after one iteration of the for loop\""]},{"cell_type":"markdown","metadata":{"id":"QlZ9m6My9CCM"},"source":["4. Using our dataloader for training a model\n","We can then use our custom dataloader for training a model. If we decide to create a model as a subclass of the nn.Module of PyTorch, and later write a train function, as in this Notebook shown in class (https://colab.research.google.com/drive/1zhDmMfSFBy3clH-NRp9nXruQXnckZ3X1#scrollTo=KZd049wKyFT8), then our train_loader object defined in Section 3., can be directly fed to our train function in place of the train_loader.\n","We could for instance, define a simple (probably too simple!) model below.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjNr6W_f9Dhh"},"outputs":[],"source":["# A simple mode\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Conv2D: 1 input channel, 8 output channels, 3 by 3 kernel, stride of 1.\n","        self.conv1 = nn.Conv2d(1, 4, 3, 1)\n","        self.fc1 = nn.Linear(87616, 2)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        output = F.log_softmax(x, dim = 1)\n","        return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"134lYPoF9Fy0"},"outputs":[],"source":["# Create model\n","model = Net()"]},{"cell_type":"markdown","metadata":{"id":"Z5ey86mlA181"},"source":["\n","Later on, we will probably have to write a train function, which will implement a mini-batch loop, which resembles the one below. It will simply iterate on the DataLoader we have defined earlier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpn7dCmi9H5Q"},"outputs":[],"source":["# Try model on one mini-batch\n","for batch_idx, (images_data, target_labels) in enumerate(train_loader):\n","    predicted_labels = model(images_data)\n","    print(predicted_labels)\n","    print(target_labels)\n","    # Forced stop\n","    break\n","    #assert False, \"Forced stop after one iteration of the mini-batch for loop\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":864,"status":"ok","timestamp":1616065120997,"user":{"displayName":"Tan Sok Ming Jamie","photoUrl":"","userId":"10980781131305532486"},"user_tz":-480},"id":"rlD22hgP7Uw-"},"outputs":[],"source":["# DEPRECATED\n","class Lung_Train_Dataset(Dataset):\n","    \n","    def __init__(self):\n","        \"\"\"\n","        Constructor for generic Dataset class - simply assembles\n","        the important parameters in attributes.\n","        \"\"\"\n","        \n","        # All images are of size 150 x 150\n","        self.img_size = (150, 150)\n","        \n","        # Only two classes will be considered here (normal and infected)\n","        self.classes = {0: 'normal', 1: 'infected_covid', 2: 'infected_noncovid'}\n","        \n","        # The dataset consists only of training images\n","        self.groups = 'train'\n","        \n","        # Number of images in each part of the dataset\n","        self.dataset_numbers = {'train_normal': 1341,\\\n","                                'train_infected_covid': 1345,\\\n","                                'train_infected_noncovid': 2530}\n","        \n","        # Path to images for different parts of the dataset\n","        self.dataset_paths = {'train_normal': './dataset/train/normal/',\\\n","                              'train_infected_covid': './dataset/train/infected/covid/',\\\n","                              'train_infected_noncovid': './dataset/train/infected/non-covid'}\n","                                                   \n","        \n","    def describe(self):\n","        \"\"\"\n","        Descriptor function.\n","        Will print details about the dataset when called.\n","        \"\"\"\n","        \n","        # Generate description\n","        msg = \"This is the training dataset of the Lung Dataset\"\n","        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n","        msg += \" in Feb-March 2021. \\n\"\n","        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n","        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n","        msg += \"The images are stored in the following locations \"\n","        msg += \"and each one contains the following number of images:\\n\"\n","        for key, val in self.dataset_paths.items():\n","            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n","        print(msg)\n","\n","\n","    def transform_img(self, transforms_list, random_seed = 1):\n","        \"\"\"\n","        Image transformation function.\n","        Transforms images with specified list of transformations\n","        \"\"\"\n","\n","        # Asserts that list of transformations must be passed into the method\n","        err_msg = \"Error - transforms_list argument cannot be an empty list.\"\n","        assert len(transforms_list) != 0, err_msg\n","\n","        # Data augmentation\n","        torch.manual_seed(random_seed)\n","        transformed_normal = []\n","        transformed_infected_covid = []\n","        transformed_infected_noncovid = []\n","        for i in tqdm(range(len(self))):\n","            img, one_hot_vector = self[i]\n","            transformations = transforms.Compose(transforms_list) # chain of image transformations\n","            transformed_img = transformations(img) # returns copy of image in Tensor form, does not change self/original image\n","            if one_hot_vector[0] == 1:\n","                transformed_normal.append(transformed_img)\n","            elif one_hot_vector[1] == 1:\n","                transformed_infected_covid.append(transformed_img)\n","            elif one_hot_vector[2] == 1:\n","                transformed_infected_noncovid.append(transformed_img)\n","        # transformed_normal = Torch.FloatTensor(transformed_normal)\n","        # transformed_infected_covid = Torch.FloatTensor(transformed_infected_covid)\n","        # transformed_infected_noncovid. Torch.FloatTensor(transformed_infected_noncovid)\n","        print(len(transformed_normal), len(transformed_infected_covid), len(transformed_infected_noncovid))\n","        return transformed_normal, transformed_infected_covid, transformed_infected_noncovid\n","\n","    \n","    def open_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'train', 'test' or 'val'.\n","        - class_val variable should be set to 'normal' or 'infected'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \n","        Returns loaded image as a normalized Numpy array.\n","        \"\"\"\n","        \n","        # Asserts checking for consistency in passed parameters\n","        err_msg = \"Error - group_val variable should be set to 'train'.\"\n","        assert group_val in self.groups, err_msg\n","        \n","        err_msg = \"Error - class_val variable should be set to 'normal', 'infected_covid', or 'infected_noncovid.\"\n","        assert class_val in self.classes.values(), err_msg\n","        \n","        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n","        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n","        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n","        assert isinstance(index_val, int), err_msg\n","        assert index_val >= 0 and index_val <= max_val, err_msg\n","        \n","        # Open file as before\n","        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n","        with open(path_to_file, 'rb') as f:\n","            im = np.asarray(Image.open(f))/255\n","        f.close()\n","        return im\n","\n","    \n","    def show_img(self, group_val, class_val, index_val):\n","        \"\"\"\n","        Opens, then displays image with specified parameters.\n","        \n","        Parameters:\n","        - group_val should take values in 'train', 'test' or 'val'.\n","        - class_val variable should be set to 'normal' or 'infected'.\n","        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n","        \"\"\"\n","        \n","        # Open image\n","        im = self.open_img(group_val, class_val, index_val)\n","        \n","        # Display\n","        plt.imshow(im)\n","\n","           \n","    def __len__(self):\n","        \"\"\"\n","        Length special method, returns the number of images in dataset.\n","        \"\"\"\n","        \n","        # Length function\n","        return sum(self.dataset_numbers.values())\n","    \n","    \n","    def __getitem__(self, index):\n","        \"\"\"\n","        Getitem special method.\n","        \n","        Expects an integer value index, between 0 and len(self) - 1.\n","        \n","        Convention:\n","        - open the image in ./dataset/train/normal/XXX.jpg if XXX is strictly lower than 1341 (number of images in the ./dataset/train/normal/ folder)\n","        - open the image in ./dataset/train/infected/YYY.jpg if XXX is between 1341 (inclusive) and 2686 (exclusive) (total number of images in \n","          ./dataset/train/normal and ./dataset/train/infected/covid/ folders), where YYY is defined as YYY = XXX - 1341.\n","        - otherwise, open the image in ./dataset/train/infected/non-covid/ folder \n","\n","        \n","        Returns the image and its label as a one hot vector, both\n","        in torch tensor format in dataset.\n","        \"\"\"\n","\n","        # Get item special method\n","        first_val = int(list(self.dataset_numbers.values())[0]) # number of images in class 0: normal\n","        second_val = int(list(self.dataset_numbers.values())[1]) # number of images in class 1: infected_covid\n","        if index < first_val: # not inclusive because image labelling starts from 0, not 1\n","            class_val = 'normal'\n","            label = torch.Tensor([1, 0, 0])\n","        elif first_val <= index < first_val + second_val:\n","            index -= first_val\n","            class_val = 'infected_covid'\n","            label = torch.Tensor([0, 1, 0])\n","        else:\n","            class_val = 'infected_noncovid'\n","            index -= (first_val + second_val)\n","            label = torch.Tensor([0, 0, 1])\n","        im = self.open_img(self.groups, class_val, index)\n","        im = transforms.functional.to_tensor(im).float()\n","        return im, label"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import OrderedDict\n","\n","\n","class ConvNetV1(nn.Module):\n","    def __init__(self, \n","                 no_of_layers: int):\n","        super(ConvNetV1, self).__init__()\n","        output_channels = [64, 64, 64, 128, 128, 256, 256, 512, 512]\n","\n","        if no_of_layers > len(output_channels):\n","            raise ValueError(f\"no_of_layers must be less than {len(output_channels)}\")\n","        self.conv0 = nn.Conv2d(1, output_channels[0], 7, stride=2)\n","        self.maxpool0 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        \n","        if no_of_layers > 0:\n","            layers = OrderedDict()\n","            for i in range(no_of_layers):\n","                layers[f\"{i+1}\"] = nn.Conv2d(output_channels[i], output_channels[i+1], 3)\n","            self.layers = nn.Sequential(layers)\n","        \n","        self.fc = nn.Linear(output_channels[no_of_layers], 2)\n","        print(self)\n","\n","    def forward(self, x):\n","        x = self.conv0(x)\n","        x = self.maxpool0(x)\n","        x = self.layers(x)\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        output = F.log_softmax(x, dim = 1)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","\n","def extract_labels(labels_all, pos_label):\n","    if pos_label == \"infected\":\n","        flipped_labels = labels_all[:, 0]\n","        labels = torch.where(flipped_labels == 0, torch.ones(1), torch.zeros(1))\n","        return torch.stack([flipped_labels, labels], dim=1)\n","    elif pos_label == \"covid\":\n","        labels = labels_all[:, 1]\n","        flipped_labels = torch.where(labels == 0, torch.ones(1), torch.zeros(1))\n","        return torch.stack([flipped_labels, labels], dim=1)\n","    else:\n","        raise ValueError(f\"{pos_label} is not a valid positive label\")\n","\n","# define test function \n","def test(model, test_loader, criterion, device, pos_label):\n","    test_loss = 0\n","    accuracy = 0\n","    \n","    for images, labels in test_loader:\n","        labels = extract_labels(labels, pos_label)\n","        images, labels = images.to(device), labels.to(device)\n","        \n","        output = model.forward(images)\n","        test_loss += criterion(output, labels).item()\n","        \n","        # output = torch.exp(output)\n","        output = output.argmax(1)\n","        output = F.one_hot(output, num_classes=2)\n","        equality = torch.all(torch.eq(labels, output),  dim=1)\n","        accuracy += equality.type(torch.FloatTensor).mean()\n","\n","    test_loss /= len(test_loader)\n","    accuracy /= len(test_loader)\n","\n","    return test_loss, accuracy\n","\n","# define train function\n","def train(model, train_loader, test_loader, no_of_epochs, pos_label, pos_weight, eval_every, device=\"cuda\"):\n","    model.to(device)\n","\n","    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","    optimizer = optim.Adam(model.parameters())\n","\n","    criterion.to(device)\n","\n","    steps = 1\n","    running_loss = 0\n","    # eval_every = 40\n","\n","    train_loss_store, test_loss_store, test_acc_store = [], [], []\n","\n","    start = time.time()\n","    for epoch in range(1, no_of_epochs+1):\n","        # print(f\"Epoch {epoch}:\")\n","        model.train()\n","        for images, labels in train_loader:\n","            labels = extract_labels(labels, pos_label)\n","            images, labels = images.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            \n","            output = model.forward(images)\n","            loss = criterion(output, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            if steps % eval_every == 0:\n","                # Eval mode for predictions\n","                model.eval()\n","\n","                # Turn off gradients for test\n","                with torch.no_grad():\n","                    test_loss, accuracy = test(model, test_loader, criterion, device, pos_label)\n","\n","                train_loss_store.append(running_loss/eval_every)\n","                test_loss_store.append(test_loss)\n","                test_acc_store.append(accuracy)\n","\n","                print(\"Epoch: {}/{} - \".format(epoch, no_of_epochs),\n","                      \"Training Loss: {:.3f} - \".format(train_loss_store[-1]),\n","                      \"Test Loss: {:.3f} - \".format(test_loss_store[-1]),\n","                      \"Test Accuracy: {:.3f}\".format(test_acc_store[-1]))\n","\n","                running_loss = 0\n","\n","                # Make sure training is back on\n","                model.train()\n","                # break\n","\n","            steps += 1\n","        # break\n","\n","    print(f\"Run time: {(time.time() - start)/60:.3f} min\")\n","    \n","    return train_loss_store, test_loss_store, test_acc_store\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pos_weight = torch.tensor([1, 2])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 40\n","eval_every = 40\n","\n","stats_store = {\n","    \"train_loss\": {},\n","    \"test_loss\": {},\n","    \"test_acc\": {},\n","}\n","\n","for i in range(8):\n","    train_loss, test_loss, test_acc = train(ConvNetV1(i+1), normalized_train_loader, normalized_test_loader, epochs, \"infected\", pos_weight, eval_every)\n","    stats_store[\"train_loss\"][f\"ConvNetV1_{i+1}\"] = train_loss\n","    stats_store[\"test_loss\"][f\"ConvNetV1_{i+1}\"] = test_loss\n","    stats_store[\"test_acc\"][f\"ConvNetV1_{i+1}\"] = test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["stats_store"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_vals = list(range(eval_every, len(train_loader)*epochs, eval_every))\n","\n","train_loss_fig = plt.figure()\n","train_loss_ax = train_loss_fig.add_subplot()\n","train_loss_ax.title.set_text('Graph of Train Loss Against Batch No.')\n","train_loss_ax.set_ylabel('train loss')\n","train_loss_ax.set_xlabel('batch no.')\n","\n","test_loss_fig = plt.figure()\n","test_loss_ax = test_loss_fig.add_subplot()\n","test_loss_ax.title.set_text('Graph of Test Loss Against Batch No.')\n","test_loss_ax.set_ylabel('test loss')\n","test_loss_ax.set_xlabel('batch no.')\n","\n","test_acc_fig = plt.figure()\n","test_acc_ax = test_acc_fig.add_subplot()\n","test_acc_ax.title.set_text('Graph of Test Accuracy Against Batch No.')\n","test_acc_ax.set_ylabel('test accuracy')\n","test_acc_ax.set_xlabel('batch no.')\n","\n","for i in range(8):\n","    train_loss_ax.plot(x_vals, stats_store[\"train_loss\"][f\"ConvNetV1_{i+1}\"], label = f\"ConvNetV1_{i+1}\")\n","    test_loss_ax.plot(x_vals, stats_store[\"test_loss\"][f\"ConvNetV1_{i+1}\"], label = f\"ConvNetV1_{i+1}\")\n","    test_acc_ax.plot(x_vals, stats_store[\"test_acc\"][f\"ConvNetV1_{i+1}\"], label = f\"ConvNetV1_{i+1}\")\n","\n","# show a legend on the plot\n","train_loss_ax.legend()\n","test_loss_ax.legend()\n","test_acc_ax.legend()\n","# Display a figure.\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Small Project.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.6 64-bit ('dl': conda)","metadata":{"interpreter":{"hash":"9bdb71cc335c0ff538946176ad679f1f73afaf0a37ebb6555520787290f7e82f"}},"name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01b6782f5ce64715bd405474adc0b75d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01df481d116e4efcb2a78cfb335f7b13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06addbf99ba842928cffb355ff0e5e18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d14401adfec48ceaa132b9af5177a32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"1769dacd972248b0b2333706e38e2057":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"1db1cd4ef6ec47a39ec49cdcbdfdbad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"221df44f0ca54bb693cbc5979a3f87c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06addbf99ba842928cffb355ff0e5e18","placeholder":"​","style":"IPY_MODEL_b4690a0bd73341a8afadf5151d48d9ca","value":" 154/154 [00:22&lt;00:00,  6.94it/s]"}},"27a5f89961764867b8c410f84d7eff8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c07510cb5ea4421a0d8e24d959dac00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47b762d59b734cbdaa0a1a1f156f53c9","placeholder":"​","style":"IPY_MODEL_ce96e58e310746ee9c5678d1961febea","value":" 2608/2608 [00:27&lt;00:00, 93.74it/s]"}},"2cc55ef68851456798e6c4ea48b77499":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38f37aff2bce411c8a1f16694606cd59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39745a6d879b44f0995ca4b441d3f23c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d67ac8f9188a4f00b25a518848ea63a6","IPY_MODEL_e245d050e4f8449bac182e2991a4c12e"],"layout":"IPY_MODEL_46f77aedb96949f0b3cad782c272f53a"}},"3f888896c37045c89be2896302a892e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"439b03ed6e9f420e99b52139b093aef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f77aedb96949f0b3cad782c272f53a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4745c7c8677c4b1da222bb20865454b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4adf8674909b46d294bb81f4fe399a9b","IPY_MODEL_5ce8ccdb53c54b3e89259e5f00d0ef08"],"layout":"IPY_MODEL_79bb442c13124e479f3cb3cf976ebc54"}},"47b762d59b734cbdaa0a1a1f156f53c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4adf8674909b46d294bb81f4fe399a9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_e9957791eaf843f6803edbcf032e0216","max":2608,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b404cbff3f2f4b4188d870952579fabc","value":2608}},"5676e84b3dfb48169c7ec928ebb2219e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_27a5f89961764867b8c410f84d7eff8b","max":154,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d84f5bb64c2413c8f770f5f1c3501ac","value":154}},"5bd20aa53a6647008d5766403c38b6d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ce8ccdb53c54b3e89259e5f00d0ef08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d57beb3500a40ecaf73265ce5c645eb","placeholder":"​","style":"IPY_MODEL_5e962112fdd34eb39d3893a9e6fa1836","value":" 2608/2608 [00:27&lt;00:00, 94.66it/s]"}},"5d57beb3500a40ecaf73265ce5c645eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e962112fdd34eb39d3893a9e6fa1836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67d5e4cbbef446d2ae91fea28e1acbc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ccb88010d5e4ecab53fdac00ad67e96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6db8105b70774514a4a52f93bb701216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74fe9c2eb9694790a3e7cdfa29611cfa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_d7f1683ed6774bb9b666731f62636b9d","max":154,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccf276a88efd4beba07bc67f1ceadef0","value":154}},"75d7811d32024ce998317b524dab04f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79bb442c13124e479f3cb3cf976ebc54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80e3f40f5a294186b75b85d868f74df4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_c46dc91e0fed45c393de58d6114832e7","max":2608,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d14401adfec48ceaa132b9af5177a32","value":2608}},"82105a57910a4f2e8842c4fc65a3194f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"87ac14f07d7e4841847473ce94dae4f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"90bf363dc92f4e31bbbed60a62a523f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74fe9c2eb9694790a3e7cdfa29611cfa","IPY_MODEL_221df44f0ca54bb693cbc5979a3f87c7"],"layout":"IPY_MODEL_6ccb88010d5e4ecab53fdac00ad67e96"}},"9d6184711dfb49988fb7f3e0bc20a2e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80e3f40f5a294186b75b85d868f74df4","IPY_MODEL_e872c1acec3c4c7bb9cda3ab79e1ca66"],"layout":"IPY_MODEL_bc4b7269e8c3417bb9e812d1e77892e4"}},"9d84f5bb64c2413c8f770f5f1c3501ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"9dc146cd31984cecbdf7da71e364d112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7f044b572084c5db1bd5f9d26b116af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1db1cd4ef6ec47a39ec49cdcbdfdbad1","placeholder":"​","style":"IPY_MODEL_aa11c3efded6486fa817631e6100ff38","value":" 154/154 [00:23&lt;00:00,  6.55it/s]"}},"aa11c3efded6486fa817631e6100ff38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b193217fbb2848ea88c4f7720178b3be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b404cbff3f2f4b4188d870952579fabc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"b4690a0bd73341a8afadf5151d48d9ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7dffb49a48f43a58095d6b287cfd12a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b940f6c6cce1440ab0d2a864a4db5935":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_75d7811d32024ce998317b524dab04f7","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87ac14f07d7e4841847473ce94dae4f8","value":7}},"bc4b7269e8c3417bb9e812d1e77892e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be94fa274498483fb94961eb0154ab79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7dffb49a48f43a58095d6b287cfd12a","placeholder":"​","style":"IPY_MODEL_01df481d116e4efcb2a78cfb335f7b13","value":" 7/7 [00:00&lt;00:00, 23.31it/s]"}},"bf78b8ea621a43209c06d662aed64b73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c46dc91e0fed45c393de58d6114832e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6e08c90ffe14f7b81754e9b34edaf18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_fda1167717fb4235beea2a153bb1339d","max":2608,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82105a57910a4f2e8842c4fc65a3194f","value":2608}},"c7eac96b1f0b4965b227933a3f02660d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6e08c90ffe14f7b81754e9b34edaf18","IPY_MODEL_def83edf8f2b40f9a93355ac08e5b9e1"],"layout":"IPY_MODEL_b193217fbb2848ea88c4f7720178b3be"}},"ccf276a88efd4beba07bc67f1ceadef0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"cd51f5fd4fec40d7ac1c37d7b66b735f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_01b6782f5ce64715bd405474adc0b75d","max":2608,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea9697adc3764b14a6cbe2300755572a","value":2608}},"ce96e58e310746ee9c5678d1961febea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0e9c037260b4a648e841aca66230f30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b940f6c6cce1440ab0d2a864a4db5935","IPY_MODEL_be94fa274498483fb94961eb0154ab79"],"layout":"IPY_MODEL_2cc55ef68851456798e6c4ea48b77499"}},"d67ac8f9188a4f00b25a518848ea63a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_ea8c101a1592401db6f463b78003dac2","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1769dacd972248b0b2333706e38e2057","value":7}},"d7f1683ed6774bb9b666731f62636b9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd833bfd44f9461aa37701970a2cfe31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd51f5fd4fec40d7ac1c37d7b66b735f","IPY_MODEL_2c07510cb5ea4421a0d8e24d959dac00"],"layout":"IPY_MODEL_bf78b8ea621a43209c06d662aed64b73"}},"def83edf8f2b40f9a93355ac08e5b9e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_439b03ed6e9f420e99b52139b093aef9","placeholder":"​","style":"IPY_MODEL_5bd20aa53a6647008d5766403c38b6d1","value":" 2608/2608 [00:28&lt;00:00, 90.85it/s]"}},"e12bdf68a09b47178547b7e7b25195c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5676e84b3dfb48169c7ec928ebb2219e","IPY_MODEL_a7f044b572084c5db1bd5f9d26b116af"],"layout":"IPY_MODEL_6db8105b70774514a4a52f93bb701216"}},"e245d050e4f8449bac182e2991a4c12e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dc146cd31984cecbdf7da71e364d112","placeholder":"​","style":"IPY_MODEL_38f37aff2bce411c8a1f16694606cd59","value":" 7/7 [00:00&lt;00:00, 38.27it/s]"}},"e872c1acec3c4c7bb9cda3ab79e1ca66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f888896c37045c89be2896302a892e9","placeholder":"​","style":"IPY_MODEL_67d5e4cbbef446d2ae91fea28e1acbc6","value":" 2608/2608 [00:28&lt;00:00, 91.56it/s]"}},"e9957791eaf843f6803edbcf032e0216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea8c101a1592401db6f463b78003dac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea9697adc3764b14a6cbe2300755572a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"fda1167717fb4235beea2a153bb1339d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}